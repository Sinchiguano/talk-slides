\documentclass[9pt]{beamer}

\input{packages.tex}
\input{colors.tex}

\usetheme{Boadilla}
\title{Machine learning basics}
\author{G. Ch√¢tel \\ Disaitek}
\date{2019/02/13}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

  \maketitle

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

  \frametitle{Machine learning}

  Machine learning (ML) is a subfield of artificial intelligence.

  \bigskip

  \begin{description}
    \item[Intuitively] We want to \emph{learn from} and \emph{make predictions
    on} data.

      \medskip

    \item[Technically] We want to update the parameters of a model to
      make it describe our training data as well as possible (``well''
      being defined by a \emph{loss function}).
  \end{description}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Model example}

  \framesubtitle{Linear regression}

  \begin{center}
    \scalebox{1.3}{
      \input{figures/scatter_02.tex}
    }
  \end{center}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Model example}

  \framesubtitle{Decision tree}

  \begin{center}
    \includegraphics[width = 9cm]{images/decision_tree.png}
  \end{center}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Model example}

  \framesubtitle{Neural network (deep learning)}

  \begin{center}
    \scalebox{0.7}{
      \input{figures/network.tex}
    }
  \end{center}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Deep learning architecture}

  \framesubtitle{Image recognition (VGG 16)}

  \begin{center}
    \includegraphics[width = 9cm]{images/vgg16_architecture.png}
  \end{center}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Deep learning architecture}

  \framesubtitle{Hierarchized pattern recognition}

  \begin{center}
    \begin{tikzpicture}[xscale = 5.5, yscale = 2.5]
      \onslide<1>{
        \node (L1) at (0, 0) {
          \includegraphics[width = 5cm]{images/cnn_vizu_l1.jpg}
        };

        \node (T1) at (-1, 0.5) {
          Layer 1
        };
      }
      \onslide<2>{
        \node (L2) at (0, 0) {
          \includegraphics[width = 5cm]{images/cnn_vizu_l2.jpg}
        };

        \node (T2) at (-1, 0.5) {
          Layer 2
        };
            }
      \onslide<3>{
        \node (L3) at (0, 0) {
          \includegraphics[width = 5cm]{images/cnn_vizu_l3.jpg}
        };

        \node (T3) at (-1, 0.5) {
          Layer 3
        };
            }
      \onslide<4>{
        \node (L4) at (0, 0) {
          \includegraphics[width = 5cm]{images/cnn_vizu_l4.jpg}
        };
        \node (T4) at (-1, 0.5) {
          Layer 4
        };
            }
      \onslide<5>{
        \node (L5) at (0, 0) {
          \includegraphics[width = 5cm]{images/cnn_vizu_l5.jpg}
        };

        \node (T5) at (-1, 0.5) {
          Layer 5
        };
      }

      \node (VGG) at (-1, -0.5) {
        \includegraphics[width = 6cm]{images/vgg16_architecture.png}
      };
    \end{tikzpicture}
  \end{center}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

  \frametitle{Application examples}

  \framesubtitle{Supervised learning}

  \begin{itemize}
    \item Supervised tasks
      \begin{itemize}
      \item Regression

        \begin{center}
          \begin{tabular}{cc}
            \textcolor{blue}{Recommender system} & (user, book) $\to$ rating \\[0.2cm]
            \textcolor{blue}{House price} & (surface, nb rooms, city) $\to$ price \\[0.2cm]
        \end{tabular}
        \end{center}

      \item Classification

        \begin{center}
          \begin{tabular}{cc}
            \textcolor{blue}{Image classification} & pixel values $\to$ cat or dog \\[0.2cm]
            \textcolor{blue}{Text classification} & list of words $\to$ spam or valid email
          \end{tabular}
        \end{center}
      \end{itemize}
    \item Unsupervised taks

      \begin{itemize}
        \item Clustering
          \begin{center}
            \textcolor{blue}{Group clients by interests} \\[.5cm]
          \end{center}
        \item Anomaly detection
          \begin{center}
            \textcolor{blue}{Detect unusual and strange events}
          \end{center}
      \end{itemize}
  \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Deep Natural Language Processing (NLP)}

  \framesubtitle{Main ideas}

  \begin{itemize}
    \item Learning the \textcolor{blue}{semantic meaning} of words,
      \pause
      \bigskip
    \item Understanding the \textcolor{blue}{information hierarchy} related to
      the task at hand,
      \bigskip
      \pause
    \item Ability to make use of \textcolor{blue}{huge amounts of data}.
  \end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Word embeddings}

  \framesubtitle{Semantic vectors}

  We associate to each word of the vocabulary a vector which
  represents its \textcolor{blue}{meaning}.

  \begin{center}
    \begin{description}
      \item[Oven] $[-0.2, 0.6]$
      \item[Microwave] $[-0.05, 0.57]$
      \item[Garden] $[0.22, -0.5]$
      \item \dots
    \end{description}
  \end{center}

  \vspace{-.9cm}

  \begin{center}
    \includegraphics[width = 9cm]{images/word_embeddings_5.png}
  \end{center}

  \vspace{-0.5cm}
  In real applications word embedding have 100 to 300 dimensions
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Word embeddings}

  \framesubtitle{Links between concepts}

  When word embeddings are created using a large enough dataset, a lot
  of information is encoded in \textcolor{blue}{differences} between
  vectors.

  \begin{center}
    \includegraphics[width = 8cm]{images/word_embeddings_3.png}
  \end{center}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Word embeddings}

  \framesubtitle{Vector geometry}

  \begin{center}
    \includegraphics[width = 7cm]{images/word_embeddings_2.png}
  \end{center}
  \[
  king - man + woman = queen
  \]
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Word embeddings}

  \framesubtitle{Bias in the representation}

  \begin{center}
    \includegraphics[width = 10cm]{images/nurse.png} \\[.5cm]
    \includegraphics[width = 10cm]{images/firefighter.png} \\[.5cm]
    \includegraphics[width = 10cm]{images/doctor.png}
  \end{center}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{NLP tasks}

  \framesubtitle{Sentiment analysis}

  Automatized analysis of an item public perception:

  {\small
    \begin{itemize}
      \item Negative
        \begin{itemize}
          \item \textcolor{red}{Even fans of Ismail Merchant's work, I suspect,
            would have a hard time sitting through this one.}
          \item \textcolor{red}{Every conceivable mistake a director
            could make in filming opera has been perpetrated here.}
          \item \textcolor{red}{Cheap, vulgar dialogue and a plot that
            crawls along at a snail's pace.}
          \item \textcolor{red}{The material and the production itself
            are little more than routine.}
        \end{itemize}
      \item Positive
        \begin{itemize}
          \item \textcolor{cyan}{A rare and lightly entertaining look
            behind the curtain that separates comics from the people
            laughing in the crowd.}
          \item \textcolor{cyan}{Rarely, indeed almost never, is such
            high-wattage brainpower coupled with pitch-perfect acting
            and an exquisite, unfakable sense of cinema.}
          \item\textcolor{cyan}{Easily the most thoughtful fictional
            examination of the root causes of anti-Semitism ever seen
            on screen.}
        \end{itemize}
    \end{itemize}
  }
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{NLP tasks}

  \framesubtitle{Document tagging}

  Automatic tagging of documents, articles or books.

  \bigskip

  \begin{itemize}
  \item Supervised way using classification (using past labels):
    \begin{itemize}
    \item Harry Potter: \textcolor{cyan}{Child book}, \textcolor{blue}{Fantasy},
      \textcolor{red}{Aventure}, \dots
    \item Lord Of The Rings: \textcolor{blue}{Fantasy},
      \textcolor{red}{Aventure}, \dots
    \item Algorithms To Live By: \textcolor{darkgray}{Computer
      science}, \textcolor{lightgray}{Textbook}, \dots
    \end{itemize}

    \bigskip

  \item Unsupervised way using clustering (grouping books that looks the same):
    \begin{itemize}
    \item \textcolor{magenta}{Cluster 1}: Harry potter, Lord Of The
      Rings, \dots
    \item \textcolor{olive}{Cluster 2}: Algorithms To Live By, The Art
      of Computer Programming, \dots
    \item \textcolor{purple}{Cluster 3}: Tofu from Scratch, Okinawa
      Diet
    \end{itemize}
  \end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{NLP tasks}

  \framesubtitle{Search engine}

  By using the \textcolor{blue}{natural language understanding}
  capabilities of deep learning models, we can create more robust and
  performant search engines.

  \bigskip

  The matching performed by these search engines is
  \textcolor{blue}{semantic} (\textit{meaning} of the query) instead
  of \textcolor{red}{lexical} (finding \textit{exactly} the word of
  the query in documents).

  \bigskip

  \begin{center}
    \includegraphics[width = 8cm]{images/word_embeddings_4.png}
  \end{center}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{NLP tasks}

  \framesubtitle{Automatic summarization}

  \begin{center}
    Extractive summarization (copy-paste most important sentences)\\[.3cm]
    \includegraphics[width = 5.5cm]{images/extractive_summarization.png} \\[.5cm]
    Abstractive summarization (generate new sentences that synthesize information)\\[.3cm]
    \includegraphics[width = 5.5cm]{images/abstractive_summarization.png}
  \end{center}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{NLP tasks}

  \framesubtitle{Abstractive summarization using wikipedia}

  The goal is to generate the abstract (first few paragraphs) of
  Wikipedia articles from their source documents.

  \begin{center}
    \includegraphics[width = 10cm]{images/wikipedia_summarization.png}
  \end{center}

  \bigskip

  {\footnotesize \textit{Generating Wikipedia By Summarizing Long
      Sequences, Google Brain}}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{NLP tasks}

  \framesubtitle{Unsupervised abstractive summarization}

  \begin{center}
    \includegraphics[width = 7cm]{images/unsupervised_summarization.png}
  \end{center}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{NLP tasks}

  \framesubtitle{Automatic summarization}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{NLP tasks}

  \framesubtitle{Automatic summarization}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Unsupervised summarization model}

  \begin{center}
    \includegraphics[width = 12cm]{images/unsupervised_summarization_model.png}
  \end{center}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
