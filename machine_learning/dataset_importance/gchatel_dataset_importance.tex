\documentclass[9pt]{beamer}

\input{packages.tex}
\input{colors.tex}

\usetheme{Boadilla}
\title{Importance of dataset for learning algorithms}
\author[G. Châtel]{Grégory Châtel\\\vspace{0.3cm}Disaitek\\Intel AI Software Innovator\\\vspace{0.3cm}@rodgzilla\\github.com/rodgzilla}
\date{September 25th, 2018}

\setbeamertemplate{footline}[frame number]{}
\setbeamertemplate{navigation symbols}{}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

  \maketitle

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

  \tableofcontents

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Machine learning basics}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

  \frametitle{Machine learning}

  \framesubtitle{Supervised learning}

  Machine learning is a subfield of artificial intelligence.

  \bigskip

  \begin{description}
    \item[Intuitively] We want to \emph{learn from} and \emph{make predictions
    on} data.

    \medskip

    \item[Technically] We want to build a model that approximate well
      (\textit{e.g.} minimize a loss function) an unknown function for
      which we only have limited observations.
  \end{description}

  \bigskip

  To do this, we usually need a lot of \emph{data}.

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%o


\section{Popular ML tasks and their dataset}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

  \frametitle{Popular datasets for computer vision}

  \begin{description}[labelwidth=\widthof{bf series 2017, JFT-300M}]
    \setlength{\itemsep}{8pt}
    \item[1990, Statlog] $\sim$2k outdoor images
    \item[1998, MNIST] 60k B&W images of handwritten digits
    \item[2005, LabelMe] $\sim$187k scenes images
    \item[2009, ImageNet] $\sim$14M color images
    \item[2017, JFT-300M] $\sim$300M color images (internal dataset @ Google)
  \end{description}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

  \frametitle{Popular datasets for computer vision}

  \begin{description}[labelwidth=\widthof{bf series 2017, JFT-300M}]
    \setlength{\itemsep}{8pt}
    \item[1990, Statlog] $\sim$2k outdoor images
    \item[1998, MNIST] 60k B&W images of handwritten digits
    \item[2005, LabelMe] $\sim$187k scenes images
    \item[2009, ImageNet] $\sim$14M color images
    \item[2017, JFT-300M] $\sim$300M color images (internal dataset @ Google)
  \end{description}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Specific problem of dataset for NLP tasks}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Data efficiency}

\subsection{Model pre-training}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Semi supervision}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Rappel des fondamentaux (optimisation du fonction de perte qui nécessite de confronter des données labelées avec les prédictions des modèles).
%% Présentation de la taille et de la qualité des jeux de données pour les disciplines classiques du machine learning.
%% Problématique en NLP pour la qualité et la quantité de données labelées
%% Solution : Utilisation des données non labelées pour améliorer les modèles
%% Pré-entrainement des modèles sur des tâches non-supervisées
%%  Semi-supervision en utilisant les données non labelées

\end{document}
